"""ä½¿ç”¨YOLOv13è¿›è¡Œå°è£…å›¾åˆ†ç±»è¯†åˆ«"""
import re
import fitz
import shutil
import cv2
import numpy as np
import time
import json
import os
import glob
from ultralytics import YOLO
from pathlib import Path

# å¯¼å…¥ç»Ÿä¸€è·¯å¾„ç®¡ç†
try:
    from package_core.PackageExtract.yolox_onnx_py.model_paths import result_path
except ModuleNotFoundError:
    from pathlib import Path
    def result_path(*parts):
        return str(Path(__file__).resolve().parents[2] / 'Result' / Path(*parts))

IMAGE_PATH = result_path('PDF_extract', 'detr_img')
SAVE_IMG_PATH = result_path('PDF_extract', 'detr_result')
ZOOM = (3, 3)

# YOLOæ¨¡å‹é…ç½®
MODEL_PATH = "model/yolo_model/PDF_processed/best.onnx"  # ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
CONF_THRESHOLD = 0.6

# ç±»åˆ«é…ç½®ï¼ˆä¿æŒä¸DETRç›¸åŒï¼‰
VOC_CLASSES = ['BGA', 'BOTTOMVIEW', 'DETAIL', 'DFN_SON', 'Detail', 'Form', 'Note', 'Package_title', 'QFN', 'QFP',
               'SIDEVIEW', 'SOP', 'Side', 'TOPVIEW', 'Top', 'package']
DETR_KEYVIEW_CLASSES = ['BGA', 'DFN_SON', 'QFP', 'QFN', 'SOP']
DETR_VIEW_CLASSES = ['Top', 'Side', 'Detail', 'Form']

# å…¨å±€æ•°æ®å­˜å‚¨å˜é‡ï¼ˆä¿æŒä¸å˜ï¼‰
source_data = []
source_package_data = []
source_keyview_data = []
source_Top_data = []
source_Side_data = []
source_Detail_data = []
source_Note_data = []
source_Form_data = []
source_Package_title_data = []
source_TOPVIEW_data = []
source_BOTTOMVIEW_data = []
source_SIDEVIEW_data = []
source_DETAIL_data = []

# å·¥å…·å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰
def remove_dir(dir_path):
    """åˆ é™¤dir_pathæ–‡ä»¶å¤¹ï¼ˆåŒ…æ‹¬å…¶æ‰€æœ‰å­æ–‡ä»¶å¤¹åŠæ–‡ä»¶ï¼‰"""
    shutil.rmtree(dir_path)

def create_dir(dir_path):
    """åˆ›å»ºdir_pathç©ºæ–‡ä»¶å¤¹ï¼ˆè‹¥å­˜åœ¨è¯¥æ–‡ä»¶å¤¹åˆ™æ¸…ç©ºè¯¥æ–‡ä»¶å¤¹ï¼‰"""
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)
    else:
        shutil.rmtree(dir_path)
        os.makedirs(dir_path)

def pdf2img(pdf_path, pages):
    """å°†pagesåˆ—è¡¨ä¸­çš„é¡µè½¬ä¸ºå›¾ç‰‡"""
    create_dir(IMAGE_PATH)
    with fitz.open(pdf_path) as doc:
        for i in range(len(pages)):
            page = doc[pages[i]]
            mat = fitz.Matrix(ZOOM[0], ZOOM[1])
            pix = page.get_pixmap(matrix=mat, alpha=False)
            pix.save(os.path.join(IMAGE_PATH, f"{pages[i] + 1}.png"))

def natural_sort_key(s):
    """ä½¿ç”¨æ­£åˆ™åŒ¹é…æ–‡ä»¶åä¸­çš„æ•°å­—"""
    int_part = re.search(r'\d+', s).group()
    return int(int_part)

def init_data_storage():
    """åˆå§‹åŒ–æ•°æ®å­˜å‚¨"""
    global source_data, source_package_data, source_keyview_data
    global source_Top_data, source_Side_data, source_Detail_data
    global source_Note_data, source_Form_data, source_Package_title_data
    global source_TOPVIEW_data, source_BOTTOMVIEW_data, source_SIDEVIEW_data, source_DETAIL_data

    source_data = []
    source_package_data = []
    source_keyview_data = []
    source_Top_data = []
    source_Side_data = []
    source_Detail_data = []
    source_Note_data = []
    source_Form_data = []
    source_Package_title_data = []
    source_TOPVIEW_data = []
    source_BOTTOMVIEW_data = []
    source_SIDEVIEW_data = []
    source_DETAIL_data = []


def process_yolov13_detection():
    """
    è°ƒç”¨YOLOv13æ£€æµ‹ï¼ˆä½¿ç”¨Ultralyticsæ¥å£ï¼‰
    """
    global source_data, source_package_data, source_keyview_data
    global source_Top_data, source_Side_data, source_Detail_data
    global source_Note_data, source_Form_data, source_Package_title_data
    global source_TOPVIEW_data, source_BOTTOMVIEW_data, source_SIDEVIEW_data, source_DETAIL_data

    yolov13_start = time.time()

    # åˆ›å»ºä¿å­˜ç»“æœçš„ç›®å½•
    create_dir(SAVE_IMG_PATH)

    # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(IMAGE_PATH) or not os.listdir(IMAGE_PATH):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶å¤¹ä¸ºç©ºæˆ–ä¸å­˜åœ¨: {IMAGE_PATH}")
        return

    # åŠ è½½YOLOæ¨¡å‹
    print("ğŸ”„ åŠ è½½YOLOv13æ¨¡å‹...")
    model = YOLO(MODEL_PATH)

    # è·å–å›¾ç‰‡åˆ—è¡¨
    image_paths = glob.glob(os.path.join(IMAGE_PATH, "*.*"))
    image_paths = [p for p in image_paths if p.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tiff'))]

    # è¿›è¡Œæ¨ç†
    print("ğŸ”„ å¼€å§‹æ¨ç†...")
    results = model.predict(
        source=IMAGE_PATH,
        conf=CONF_THRESHOLD,
        save=True,
        project=SAVE_IMG_PATH,
        name="predictions",
        exist_ok=True,
        verbose=False
    )

    # å¤„ç†æ£€æµ‹ç»“æœ
    for i, result in enumerate(results):
        if not result.boxes:
            continue

        # è·å–å›¾ç‰‡æ–‡ä»¶åå’Œé¡µç 
        img_path = result.path
        img_name = os.path.basename(img_path)
        page_num = int(os.path.splitext(img_name)[0]) - 1  # è½¬æ¢ä¸º0-basedé¡µç 

        # è·å–æ£€æµ‹æ¡†ä¿¡æ¯
        boxes = result.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]
        confidences = result.boxes.conf.cpu().numpy()
        class_ids = result.boxes.cls.cpu().numpy().astype(int)

        for j in range(len(boxes)):
            box = boxes[j]
            score = confidences[j]
            label_id = class_ids[j]

            # è·å–ç±»åˆ«åç§°
            class_name = result.names[label_id] if label_id in result.names else f"ID:{label_id}"

            # è¿‡æ»¤ç½®ä¿¡åº¦å°äº0.6å¹¶ä¸”æ ‡ç­¾åç§°ä¸ºpackageçš„æ£€æµ‹ç»“æœ
            if class_name == 'package' and score < 0.6:
                continue

            # è°ƒæ•´åæ ‡åˆ°åŸå§‹PDFå°ºå¯¸ï¼ˆè€ƒè™‘ZOOMç¼©æ”¾ï¼‰
            adjusted_pos = [
                int(box[0] / ZOOM[0]),
                int(box[1] / ZOOM[1]),
                int(box[2] / ZOOM[0]),
                int(box[3] / ZOOM[1])
            ]

            # å­˜å‚¨æ£€æµ‹ç»“æœåˆ°source_data
            source_data.append({
                'page': page_num,
                'type': class_name,
                'detr_type': class_name,
                'pos': adjusted_pos,
                'conf': float(score)
            })

            # åˆ†ç±»å­˜å‚¨ä¸åŒç±»å‹çš„æ•°æ®
            store_detection_by_type(page_num, class_name, adjusted_pos, float(score))

    yolov13_end = time.time()
    print(f"âœ… YOLOv13æ£€æµ‹å®Œæˆï¼Œè€—æ—¶: {yolov13_end - yolov13_start:.4f}ç§’")


def store_detection_by_type(page_num, class_name, pos, score):
    """æ ¹æ®ç±»åˆ«åˆ†ç±»å­˜å‚¨æ£€æµ‹ç»“æœ"""
    global source_package_data, source_keyview_data, source_Top_data
    global source_Side_data, source_Detail_data, source_Note_data
    global source_Form_data, source_Package_title_data, source_TOPVIEW_data
    global source_BOTTOMVIEW_data, source_SIDEVIEW_data, source_DETAIL_data

    detection_item = {
        'page': page_num,
        'type': class_name,
        'detr_type': class_name,
        'pos': pos,
        'conf': score,
        'match_state': -1
    }

    if class_name == 'package':
        source_package_data.append(detection_item)
    elif class_name == 'Top':
        source_Top_data.append(detection_item)
    elif class_name == 'Side':
        source_Side_data.append(detection_item)
    elif class_name == 'Detail':
        source_Detail_data.append(detection_item)
    elif class_name == 'Note':
        source_Note_data.append(detection_item)
    elif class_name == 'Form':
        source_Form_data.append(detection_item)
    elif class_name == 'Package_title':
        source_Package_title_data.append(detection_item)
    elif class_name == 'TOPVIEW':
        source_TOPVIEW_data.append(detection_item)
    elif class_name == 'BOTTOMVIEW':
        source_BOTTOMVIEW_data.append(detection_item)
    elif class_name == 'SIDEVIEW':
        source_SIDEVIEW_data.append(detection_item)
    elif class_name == 'DETAIL':
        source_DETAIL_data.append(detection_item)
    elif class_name in DETR_KEYVIEW_CLASSES:  # å…³é”®ç‰¹å¾è§†å›¾
        source_keyview_data.append(detection_item)



def _sort_views_by_position(views):
    """æŒ‰ä½ç½®å¯¹è§†å›¾è¿›è¡Œæ’åºï¼šå…ˆä¸Šä¸‹åå·¦å³"""
    if not views:
        return []

    # æŒ‰Yåæ ‡åˆ†ç»„ï¼ˆä½¿ç”¨æ•´æ•°é™¤æ³•æ¥åˆ›å»ºåˆ†ç»„ï¼‰
    groups = {}
    for view in views:
        y_group = view['pos'][1] // 20
        if y_group not in groups:
            groups[y_group] = []
        groups[y_group].append(view)

    # æŒ‰Yåæ ‡æ’åºåˆ†ç»„ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰ï¼Œç„¶åæ¯ç»„å†…æŒ‰Xåæ ‡æ’åºï¼ˆä»å·¦åˆ°å³ï¼‰
    result = []
    for y_group in sorted(groups.keys()):
        sorted_group = sorted(groups[y_group], key=lambda x: x['pos'][0])
        result.extend(sorted_group)

    return result

def find_pages_with_features_but_no_package():
    """æ‰¾å‡ºç‰¹å¾è§†å›¾æ•°é‡ä¸packageæ•°é‡ä¸åŒ¹é…çš„é¡µé¢"""
    global source_data
    page_stats = {}

    # ç»Ÿè®¡æ¯ä¸ªé¡µé¢çš„å…ƒç´ æ•°é‡å’Œç‰¹å¾
    for item in source_data:
        page_num = item['page']
        item_type = item['type']

        if page_num not in page_stats:
            page_stats[page_num] = {
                'package_count': 0,
                'keyview_count': 0,
                'view_features_count': 0,
                'has_package': False
            }

        if item_type == 'package':
            page_stats[page_num]['package_count'] += 1
            page_stats[page_num]['has_package'] = True
        elif item_type in DETR_KEYVIEW_CLASSES:
            page_stats[page_num]['keyview_count'] += 1
        elif item_type in DETR_VIEW_CLASSES:
            page_stats[page_num]['view_features_count'] += 1

    target_pages = []

    for page_num, stats in page_stats.items():
        # å¦‚æœç‰¹å¾è§†å›¾æ•°é‡ä¸packageæ•°é‡ä¸ç›¸åŒï¼Œåˆ™æ ¹æ®åŸé€»è¾‘åˆ¤æ–­æ˜¯å¦è¿”å›é¡µç 
        if stats['keyview_count'] != stats['package_count']:
            # åŸé€»è¾‘ï¼šæœ‰å…³é”®ç‰¹å¾è§†å›¾ã€æœ‰å…¶ä»–è§†å›¾ç‰¹å¾ã€ä½†æ²¡æœ‰packageæ ‡ç­¾
            if (stats['keyview_count'] > 0 and
                    stats['view_features_count'] > 1):
                target_pages.append(page_num)

    return sorted(target_pages)


def add_minimum_bounding_boxes_for_target_pages():
    """ä¸ºç›®æ ‡é¡µé¢æ·»åŠ æœ€å°å¤–æ¥çŸ©å½¢æ¡†"""
    global source_data, source_package_data
    # é¦–å…ˆè·å–target_pages
    target_pages = find_pages_with_features_but_no_package()

    if not target_pages:
        return 0

    page_data = {}

    for page_num in target_pages:
        page_data[page_num] = {
            'all_rects': [],  # å­˜å‚¨æ‰€æœ‰éœ€è¦è®¡ç®—å¤–æ¡†çš„çŸ©å½¢
            'keyview_count': 0,
            'top_views': [],
            'keyviews': [],
            'package_count': 0
        }

    for item in source_data:
        page_num = item['page']
        if page_num in target_pages:
            rect = item['pos']
            item_type = item['type']

            # æ”¶é›†æ‰€æœ‰éœ€è¦è®¡ç®—å¤–æ¡†çš„çŸ©å½¢ï¼ˆåŒ…æ‹¬å…³é”®ç‰¹å¾å’Œè§†å›¾ç±»ï¼‰
            if item_type in DETR_KEYVIEW_CLASSES or item_type in DETR_VIEW_CLASSES:
                page_data[page_num]['all_rects'].append(rect)

            # ç»Ÿè®¡å…³é”®ç‰¹å¾è§†å›¾æ•°é‡å’Œä½ç½®
            if item_type in DETR_KEYVIEW_CLASSES:
                page_data[page_num]['keyview_count'] += 1
                page_data[page_num]['keyviews'].append({
                    'type': item_type,
                    'pos': rect
                })
            # æ”¶é›†Topè§†å›¾
            elif item_type == 'Top':
                page_data[page_num]['top_views'].append({
                    'type': item_type,
                    'pos': rect
                })
            # æ”¶é›†package
            elif item_type == 'package':
                page_data[page_num]['package_count'] += 1

    # ä¸ºæ¯ä¸ªç›®æ ‡é¡µé¢è®¡ç®—æœ€å°å¤–æ¥çŸ©å½¢æ¡†
    added_count = 0
    # existing_package_pages = {item['page'] for item in source_package_data}

    for page_num, data in page_data.items():
        # ä½¿ç”¨æ‰€æœ‰ç›¸å…³çŸ©å½¢æ¥è®¡ç®—ï¼Œè€Œä¸ä»…ä»…æ˜¯rects
        if not data['all_rects']:
            continue

        all_rects = data['all_rects']
        keyview_count = data['keyview_count']
        package_count = data['package_count']
        top_views = data['top_views']
        keyviews = data['keyviews']

        # æƒ…å†µ1ï¼šåªå­˜åœ¨ä¸€ä¸ªç‰¹å¾è§†å›¾æ—¶ï¼Œè®¡ç®—æ‰€æœ‰çŸ©å½¢æ¡†çš„æœ€å°å¤–æ¡†
        if keyview_count == 1:
            # åªæœ‰ä¸€ä¸ªå…³é”®ç‰¹å¾è§†å›¾ï¼Œè®¡ç®—æ‰€æœ‰ç›¸å…³çŸ©å½¢æ¡†çš„æœ€å°å¤–æ¥çŸ©å½¢
            bounding_rect = [
                min(rect[0] for rect in all_rects),
                min(rect[1] for rect in all_rects),
                max(rect[2] for rect in all_rects),
                max(rect[3] for rect in all_rects)
            ]

            # æ·»åŠ åˆ°source_package_data
            source_package_data.append({
                'page': page_num,
                'type': 'package',
                'detr_type': 'package',
                'pos': bounding_rect,
                'conf': 1,
                'match_state': -1
            })
            added_count += 1

        # æƒ…å†µ2ï¼šåŸé€»è¾‘ - å…³é”®ç‰¹å¾è§†å›¾æ•°é‡ > packageæ•°é‡
        elif keyview_count > package_count:
            # è®¡ç®—éœ€è¦è¡¥å……çš„packageæ•°é‡
            need_package_count = keyview_count - package_count

            if need_package_count == 1 and keyview_count == 1:
                # åªæœ‰ä¸€ä¸ªå…³é”®ç‰¹å¾è§†å›¾ï¼Œè®¡ç®—æ‰€æœ‰ç›¸å…³çŸ©å½¢æ¡†çš„æœ€å°å¤–æ¥çŸ©å½¢
                bounding_rect = [
                    min(rect[0] for rect in all_rects),
                    min(rect[1] for rect in all_rects),
                    max(rect[2] for rect in all_rects),
                    max(rect[3] for rect in all_rects)
                ]

                # æ·»åŠ åˆ°source_package_data
                source_package_data.append({
                    'page': page_num,
                    'type': 'package',
                    'detr_type': 'package',
                    'pos': bounding_rect,
                    'conf': 1,
                    'match_state': -1
                })
                added_count += 1

            elif need_package_count >= 1 and keyview_count > 1:
                # å¤šä¸ªå…³é”®ç‰¹å¾è§†å›¾ï¼Œéœ€è¦åŒ¹é…Topè§†å›¾
                sorted_top_views = _sort_views_by_position(top_views)
                sorted_keyviews = _sort_views_by_position(keyviews)

                # ä¸ºæ¯ä¸ªTopè§†å›¾å’Œå¯¹åº”çš„å…³é”®ç‰¹å¾è§†å›¾è®¡ç®—æœ€å°å¤–æ¥çŸ©å½¢
                for i, top_view in enumerate(sorted_top_views):
                    if i < len(sorted_keyviews) and i < need_package_count:
                        top_rect = top_view['pos']
                        keyview_rect = sorted_keyviews[i]['pos']

                        # è®¡ç®—è¿™ä¸¤ä¸ªçŸ©å½¢çš„æœ€å°å¤–æ¥çŸ©å½¢
                        bounding_rect = [
                            min(top_rect[0], keyview_rect[0]),
                            min(top_rect[1], keyview_rect[1]),
                            max(top_rect[2], keyview_rect[2]),
                            max(top_rect[3], keyview_rect[3])
                        ]

                        # æ·»åŠ åˆ°source_package_data
                        source_package_data.append({
                            'page': page_num,
                            'type': 'package',
                            'detr_type': 'package',
                            'pos': bounding_rect,
                            'conf': 1,
                            'match_state': -1
                        })
                        added_count += 1

    return added_count


def detect_components(pdf_path, pages):
    """
    å®Œæ•´çš„ç»„ä»¶æ£€æµ‹æµç¨‹ï¼ˆä½¿ç”¨DETRæ¨¡å‹ï¼‰
    """
    # 1. åˆå§‹åŒ–æ•°æ®å­˜å‚¨
    init_data_storage()

    # 2. è½¬æ¢PDFä¸ºå›¾ç‰‡
    pdf2img(pdf_path, pages)

    # 3. è°ƒç”¨DETRæ£€æµ‹
    process_yolov13_detection()

    # 4. ä¸ºéœ€è¦çš„é¡µé¢æ·»åŠ æœ€å°å¤–æ¥çŸ©å½¢æ¡†
    add_minimum_bounding_boxes_for_target_pages()

    # 5. ä¿å­˜æ£€æµ‹ç»“æœåˆ°JSONæ–‡ä»¶
    results = {
        'source_data': source_data,
        'source_package_data': source_package_data,
        'source_keyview_data': source_keyview_data,
        'source_Top_data': source_Top_data,
        'source_Side_data': source_Side_data,
        'source_Detail_data': source_Detail_data,
        'source_Note_data': source_Note_data,
        'source_Form_data': source_Form_data,
        'source_Package_title_data': source_Package_title_data,
        'source_TOPVIEW_data': source_TOPVIEW_data,
        'source_BOTTOMVIEW_data': source_BOTTOMVIEW_data,
        'source_SIDEVIEW_data': source_SIDEVIEW_data,
        'source_DETAIL_data': source_DETAIL_data
    }

    # 5. ä¿å­˜åˆ°JSONæ–‡ä»¶
    # with open('Result/PDF_extract/detr_detection_results0.json', 'w', encoding='utf-8') as f:
    #     json.dump(results, f, ensure_ascii=False, indent=2,
    #               default=lambda x: float(x) if isinstance(x, (np.float32, np.float64)) else x)

    # print("æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ° detr_detection_results.json")
    return results
